{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaboration and Competition\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the third project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program.\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mtensorflow 1.7.1 has requirement numpy>=1.13.3, but you'll have numpy 1.12.1 which is incompatible.\u001b[0m\r\n",
      "\u001b[31mipython 6.5.0 has requirement prompt-toolkit<2.0.0,>=1.0.15, but you'll have prompt-toolkit 2.0.9 which is incompatible.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip -q install ./python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "env = UnityEnvironment(file_name=\"/data/Tennis_Linux_NoVis/Tennis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Tennis.app\"`\n",
    "- **Windows** (x86): `\"path/to/Tennis_Windows_x86/Tennis.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Tennis_Windows_x86_64/Tennis.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Tennis_Linux/Tennis.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Tennis_Linux/Tennis.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Tennis_Linux_NoVis/Tennis.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Tennis_Linux_NoVis/Tennis.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Tennis.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Tennis.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Examine the State and Action Spaces\n",
    "In this environment, two agents control rackets to bounce a ball over a net. If an agent hits the ball over the net, it receives a reward of +0.1. If an agent lets a ball hit the ground or hits the ball out of bounds, it receives a reward of -0.01. Thus, the goal of each agent is to keep the ball in play.\n",
    "\n",
    "The observation space consists of 8 variables corresponding to the position and velocity of the ball and racket. Two continuous actions are available, corresponding to movement toward (or away from) the net, and jumping.\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Size of each action: 2\n",
      "There are 2 agents. Each observes a state with length: 24\n",
      "The state for the first agent looks like: [ 0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.         -6.65278625 -1.5        -0.          0.\n",
      "  6.83172083  6.         -0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents \n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 10\tAverage Score: 0.00\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "Episode 20\tAverage Score: 0.00\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "Episode 30\tAverage Score: 0.00\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "Episode 40\tAverage Score: 0.00\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "Episode 50\tAverage Score: 0.00\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "Episode 60\tAverage Score: 0.00\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "Episode 70\tAverage Score: 0.00\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "Episode 80\tAverage Score: 0.00\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "Episode 90\tAverage Score: 0.00\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "Episode 100\tAverage Score: 0.00\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "Episode 110\tAverage Score: 0.00\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "Episode 120\tAverage Score: 0.00\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "Episode 130\tAverage Score: 0.00\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "Episode 140\tAverage Score: 0.00\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "Episode 150\tAverage Score: 0.00\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "Episode 160\tAverage Score: 0.00\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "Episode 170\tAverage Score: 0.00\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "Episode 180\tAverage Score: 0.00\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "Episode 190\tAverage Score: 0.00\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "Episode 200\tAverage Score: 0.00\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "Episode 210\tAverage Score: 0.00\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "Episode 220\tAverage Score: 0.00\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "Episode 230\tAverage Score: 0.00\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "Episode 240\tAverage Score: 0.00\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "Episode 250\tAverage Score: 0.00\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "Episode 260\tAverage Score: 0.00\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "Episode 270\tAverage Score: 0.00\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "Episode 280\tAverage Score: 0.00\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "Episode 290\tAverage Score: 0.00\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "Episode 300\tAverage Score: 0.00\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "Episode 310\tAverage Score: 0.00\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "Episode 320\tAverage Score: 0.00\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "Episode 330\tAverage Score: 0.00\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "Episode 340\tAverage Score: 0.00\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "Episode 350\tAverage Score: 0.00\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "Episode 360\tAverage Score: 0.00\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "Episode 370\tAverage Score: 0.00\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "Episode 380\tAverage Score: 0.00\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "Episode 390\tAverage Score: 0.00\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "Episode 400\tAverage Score: 0.00\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "Episode 410\tAverage Score: 0.00\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "Episode 420\tAverage Score: 0.00\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "Episode 430\tAverage Score: 0.00\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "Episode 440\tAverage Score: 0.00\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "Episode 450\tAverage Score: 0.00\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "Episode 460\tAverage Score: 0.00\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "Episode 470\tAverage Score: 0.00\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "Episode 480\tAverage Score: 0.00\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "Episode 490\tAverage Score: 0.01\tAgent 1 Score: 0.10\tAgent 2 Score: -0.01\n",
      "Episode 500\tAverage Score: 0.01\tAgent 1 Score: 0.10\tAgent 2 Score: -0.01\n",
      "Episode 510\tAverage Score: 0.01\tAgent 1 Score: 0.10\tAgent 2 Score: -0.01\n",
      "Episode 520\tAverage Score: 0.02\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "Episode 530\tAverage Score: 0.02\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "Episode 540\tAverage Score: 0.02\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "Episode 550\tAverage Score: 0.02\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "Episode 560\tAverage Score: 0.02\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "Episode 570\tAverage Score: 0.02\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "Episode 580\tAverage Score: 0.02\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "Episode 590\tAverage Score: 0.02\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "Episode 600\tAverage Score: 0.02\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "Episode 610\tAverage Score: 0.01\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "Episode 620\tAverage Score: 0.01\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "Episode 630\tAverage Score: 0.01\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "Episode 640\tAverage Score: 0.01\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "Episode 650\tAverage Score: 0.01\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "Episode 660\tAverage Score: 0.01\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "Episode 670\tAverage Score: 0.01\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "Episode 680\tAverage Score: 0.01\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "Episode 690\tAverage Score: 0.00\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "Episode 700\tAverage Score: 0.00\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "Episode 710\tAverage Score: 0.00\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "Episode 720\tAverage Score: 0.00\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "Episode 730\tAverage Score: 0.00\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "Episode 740\tAverage Score: 0.00\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "Episode 750\tAverage Score: 0.00\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "Episode 760\tAverage Score: 0.00\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "Episode 770\tAverage Score: 0.00\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "Episode 780\tAverage Score: 0.00\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "Episode 790\tAverage Score: 0.00\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "Episode 800\tAverage Score: 0.00\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "Episode 810\tAverage Score: 0.00\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "Episode 820\tAverage Score: 0.00\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "Episode 830\tAverage Score: 0.00\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "Episode 840\tAverage Score: 0.00\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "Episode 850\tAverage Score: 0.00\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "Episode 860\tAverage Score: 0.00\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "Episode 870\tAverage Score: 0.00\tAgent 1 Score: -0.01\tAgent 2 Score: 0.10\n",
      "Episode 880\tAverage Score: 0.01\tAgent 1 Score: 0.00\tAgent 2 Score: 0.09\n",
      "Episode 890\tAverage Score: 0.01\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "Episode 900\tAverage Score: 0.01\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "Episode 910\tAverage Score: 0.01\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "Episode 920\tAverage Score: 0.02\tAgent 1 Score: 0.00\tAgent 2 Score: 0.09\n",
      "Episode 930\tAverage Score: 0.02\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "Episode 940\tAverage Score: 0.02\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "Episode 950\tAverage Score: 0.02\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "Episode 960\tAverage Score: 0.02\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "Episode 970\tAverage Score: 0.02\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "Episode 980\tAverage Score: 0.02\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "Episode 990\tAverage Score: 0.02\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "Episode 1000\tAverage Score: 0.02\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "Episode 1010\tAverage Score: 0.02\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "Episode 1020\tAverage Score: 0.01\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "Episode 1030\tAverage Score: 0.02\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "Episode 1040\tAverage Score: 0.01\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "Episode 1050\tAverage Score: 0.02\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "Episode 1060\tAverage Score: 0.03\tAgent 1 Score: 0.00\tAgent 2 Score: 0.09\n",
      "Episode 1070\tAverage Score: 0.03\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "Episode 1080\tAverage Score: 0.04\tAgent 1 Score: -0.01\tAgent 2 Score: 0.10\n",
      "Episode 1090\tAverage Score: 0.04\tAgent 1 Score: 0.10\tAgent 2 Score: -0.01\n",
      "Episode 1100\tAverage Score: 0.05\tAgent 1 Score: 0.10\tAgent 2 Score: 0.19\n",
      "Episode 1110\tAverage Score: 0.06\tAgent 1 Score: 0.10\tAgent 2 Score: -0.01\n",
      "Episode 1120\tAverage Score: 0.07\tAgent 1 Score: 0.10\tAgent 2 Score: -0.01\n",
      "Episode 1130\tAverage Score: 0.08\tAgent 1 Score: 0.10\tAgent 2 Score: -0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1140\tAverage Score: 0.09\tAgent 1 Score: 0.10\tAgent 2 Score: 0.09\n",
      "Episode 1150\tAverage Score: 0.09\tAgent 1 Score: 0.10\tAgent 2 Score: -0.01\n",
      "Episode 1160\tAverage Score: 0.09\tAgent 1 Score: 0.09\tAgent 2 Score: 0.10\n",
      "Episode 1170\tAverage Score: 0.09\tAgent 1 Score: 0.10\tAgent 2 Score: -0.01\n",
      "Episode 1180\tAverage Score: 0.10\tAgent 1 Score: 0.09\tAgent 2 Score: 0.10\n",
      "Episode 1190\tAverage Score: 0.11\tAgent 1 Score: 0.20\tAgent 2 Score: 0.19\n",
      "Episode 1200\tAverage Score: 0.11\tAgent 1 Score: 0.30\tAgent 2 Score: 0.19\n",
      "Episode 1210\tAverage Score: 0.13\tAgent 1 Score: 0.39\tAgent 2 Score: 0.50\n",
      "Episode 1220\tAverage Score: 0.14\tAgent 1 Score: 0.19\tAgent 2 Score: 0.30\n",
      "Episode 1230\tAverage Score: 0.16\tAgent 1 Score: 0.60\tAgent 2 Score: 0.59\n",
      "Episode 1240\tAverage Score: 0.16\tAgent 1 Score: 0.19\tAgent 2 Score: 0.30\n",
      "Episode 1250\tAverage Score: 0.17\tAgent 1 Score: 0.20\tAgent 2 Score: 0.09\n",
      "Episode 1260\tAverage Score: 0.18\tAgent 1 Score: 0.30\tAgent 2 Score: 0.19\n",
      "Episode 1270\tAverage Score: 0.20\tAgent 1 Score: 0.19\tAgent 2 Score: 0.20\n",
      "Episode 1280\tAverage Score: 0.24\tAgent 1 Score: 0.80\tAgent 2 Score: 0.79\n",
      "Episode 1290\tAverage Score: 0.32\tAgent 1 Score: 0.40\tAgent 2 Score: 0.49\n",
      "Episode 1300\tAverage Score: 0.38\tAgent 1 Score: 0.20\tAgent 2 Score: -0.01\n",
      "Episode 1310\tAverage Score: 0.39\tAgent 1 Score: 0.09\tAgent 2 Score: 0.10\n",
      "Episode 1320\tAverage Score: 0.43\tAgent 1 Score: 0.70\tAgent 2 Score: 0.69\n",
      "\n",
      " Environment solved in 1326 episodes! \t Average Score: 0.506800\n",
      "\n",
      " Environment solved in 1327 episodes! \t Average Score: 0.506800\n",
      "\n",
      " Environment solved in 1328 episodes! \t Average Score: 0.505800\n",
      "\n",
      " Environment solved in 1329 episodes! \t Average Score: 0.505800\n",
      "Episode 1330\tAverage Score: 0.50\tAgent 1 Score: -0.01\tAgent 2 Score: 0.10\n",
      "\n",
      " Environment solved in 1330 episodes! \t Average Score: 0.500800\n",
      "\n",
      " Environment solved in 1331 episodes! \t Average Score: 0.500800\n",
      "\n",
      " Environment solved in 1332 episodes! \t Average Score: 0.501800\n",
      "\n",
      " Environment solved in 1333 episodes! \t Average Score: 0.502800\n",
      "\n",
      " Environment solved in 1334 episodes! \t Average Score: 0.503800\n",
      "\n",
      " Environment solved in 1335 episodes! \t Average Score: 0.503800\n",
      "\n",
      " Environment solved in 1336 episodes! \t Average Score: 0.503800\n",
      "\n",
      " Environment solved in 1337 episodes! \t Average Score: 0.503800\n",
      "\n",
      " Environment solved in 1338 episodes! \t Average Score: 0.509800\n",
      "\n",
      " Environment solved in 1339 episodes! \t Average Score: 0.509800\n",
      "Episode 1340\tAverage Score: 0.52\tAgent 1 Score: 1.40\tAgent 2 Score: 1.39\n",
      "\n",
      " Environment solved in 1340 episodes! \t Average Score: 0.520800\n",
      "\n",
      " Environment solved in 1341 episodes! \t Average Score: 0.533800\n",
      "\n",
      " Environment solved in 1342 episodes! \t Average Score: 0.553800\n",
      "\n",
      " Environment solved in 1343 episodes! \t Average Score: 0.578800\n",
      "\n",
      " Environment solved in 1344 episodes! \t Average Score: 0.603800\n",
      "\n",
      " Environment solved in 1345 episodes! \t Average Score: 0.604800\n",
      "\n",
      " Environment solved in 1346 episodes! \t Average Score: 0.629800\n",
      "\n",
      " Environment solved in 1347 episodes! \t Average Score: 0.654800\n",
      "\n",
      " Environment solved in 1348 episodes! \t Average Score: 0.653800\n",
      "\n",
      " Environment solved in 1349 episodes! \t Average Score: 0.678800\n",
      "Episode 1350\tAverage Score: 0.69\tAgent 1 Score: 1.59\tAgent 2 Score: 1.70\n",
      "\n",
      " Environment solved in 1350 episodes! \t Average Score: 0.693800\n",
      "\n",
      " Environment solved in 1351 episodes! \t Average Score: 0.694800\n",
      "\n",
      " Environment solved in 1352 episodes! \t Average Score: 0.696800\n",
      "\n",
      " Environment solved in 1353 episodes! \t Average Score: 0.703800\n",
      "\n",
      " Environment solved in 1354 episodes! \t Average Score: 0.707800\n",
      "\n",
      " Environment solved in 1355 episodes! \t Average Score: 0.704800\n",
      "\n",
      " Environment solved in 1356 episodes! \t Average Score: 0.710800\n",
      "\n",
      " Environment solved in 1357 episodes! \t Average Score: 0.735800\n",
      "\n",
      " Environment solved in 1358 episodes! \t Average Score: 0.761800\n",
      "\n",
      " Environment solved in 1359 episodes! \t Average Score: 0.784800\n",
      "Episode 1360\tAverage Score: 0.78\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "\n",
      " Environment solved in 1360 episodes! \t Average Score: 0.781800\n",
      "\n",
      " Environment solved in 1361 episodes! \t Average Score: 0.782800\n",
      "\n",
      " Environment solved in 1362 episodes! \t Average Score: 0.788800\n",
      "\n",
      " Environment solved in 1363 episodes! \t Average Score: 0.790800\n",
      "\n",
      " Environment solved in 1364 episodes! \t Average Score: 0.792800\n",
      "\n",
      " Environment solved in 1365 episodes! \t Average Score: 0.794800\n",
      "\n",
      " Environment solved in 1366 episodes! \t Average Score: 0.788800\n",
      "\n",
      " Environment solved in 1367 episodes! \t Average Score: 0.787800\n",
      "\n",
      " Environment solved in 1368 episodes! \t Average Score: 0.796800\n",
      "\n",
      " Environment solved in 1369 episodes! \t Average Score: 0.795800\n",
      "Episode 1370\tAverage Score: 0.80\tAgent 1 Score: 0.59\tAgent 2 Score: 0.70\n",
      "\n",
      " Environment solved in 1370 episodes! \t Average Score: 0.800800\n",
      "\n",
      " Environment solved in 1371 episodes! \t Average Score: 0.783800\n",
      "\n",
      " Environment solved in 1372 episodes! \t Average Score: 0.796800\n",
      "\n",
      " Environment solved in 1373 episodes! \t Average Score: 0.799700\n",
      "\n",
      " Environment solved in 1374 episodes! \t Average Score: 0.804700\n",
      "\n",
      " Environment solved in 1375 episodes! \t Average Score: 0.804700\n",
      "\n",
      " Environment solved in 1376 episodes! \t Average Score: 0.796700\n",
      "\n",
      " Environment solved in 1377 episodes! \t Average Score: 0.791700\n",
      "\n",
      " Environment solved in 1378 episodes! \t Average Score: 0.795600\n",
      "\n",
      " Environment solved in 1379 episodes! \t Average Score: 0.811600\n",
      "Episode 1380\tAverage Score: 0.81\tAgent 1 Score: 0.79\tAgent 2 Score: 0.80\n",
      "\n",
      " Environment solved in 1380 episodes! \t Average Score: 0.811600\n",
      "\n",
      " Environment solved in 1381 episodes! \t Average Score: 0.813600\n",
      "\n",
      " Environment solved in 1382 episodes! \t Average Score: 0.790600\n",
      "\n",
      " Environment solved in 1383 episodes! \t Average Score: 0.772600\n",
      "\n",
      " Environment solved in 1384 episodes! \t Average Score: 0.773500\n",
      "\n",
      " Environment solved in 1385 episodes! \t Average Score: 0.778500\n",
      "\n",
      " Environment solved in 1386 episodes! \t Average Score: 0.775500\n",
      "\n",
      " Environment solved in 1387 episodes! \t Average Score: 0.772500\n",
      "\n",
      " Environment solved in 1388 episodes! \t Average Score: 0.759400\n",
      "\n",
      " Environment solved in 1389 episodes! \t Average Score: 0.753400\n",
      "Episode 1390\tAverage Score: 0.75\tAgent 1 Score: 0.10\tAgent 2 Score: -0.01\n",
      "\n",
      " Environment solved in 1390 episodes! \t Average Score: 0.749500\n",
      "\n",
      " Environment solved in 1391 episodes! \t Average Score: 0.743500\n",
      "\n",
      " Environment solved in 1392 episodes! \t Average Score: 0.744500\n",
      "\n",
      " Environment solved in 1393 episodes! \t Average Score: 0.735500\n",
      "\n",
      " Environment solved in 1394 episodes! \t Average Score: 0.734500\n",
      "\n",
      " Environment solved in 1395 episodes! \t Average Score: 0.731500\n",
      "\n",
      " Environment solved in 1396 episodes! \t Average Score: 0.728500\n",
      "\n",
      " Environment solved in 1397 episodes! \t Average Score: 0.707500\n",
      "\n",
      " Environment solved in 1398 episodes! \t Average Score: 0.698600\n",
      "\n",
      " Environment solved in 1399 episodes! \t Average Score: 0.701600\n",
      "Episode 1400\tAverage Score: 0.70\tAgent 1 Score: 0.10\tAgent 2 Score: -0.01\n",
      "\n",
      " Environment solved in 1400 episodes! \t Average Score: 0.700600\n",
      "\n",
      " Environment solved in 1401 episodes! \t Average Score: 0.707600\n",
      "\n",
      " Environment solved in 1402 episodes! \t Average Score: 0.702600\n",
      "\n",
      " Environment solved in 1403 episodes! \t Average Score: 0.702600\n",
      "\n",
      " Environment solved in 1404 episodes! \t Average Score: 0.709600\n",
      "\n",
      " Environment solved in 1405 episodes! \t Average Score: 0.711600\n",
      "\n",
      " Environment solved in 1406 episodes! \t Average Score: 0.711500\n",
      "\n",
      " Environment solved in 1407 episodes! \t Average Score: 0.703500\n",
      "\n",
      " Environment solved in 1408 episodes! \t Average Score: 0.699400\n",
      "\n",
      " Environment solved in 1409 episodes! \t Average Score: 0.699400\n",
      "Episode 1410\tAverage Score: 0.70\tAgent 1 Score: -0.01\tAgent 2 Score: 0.10\n",
      "\n",
      " Environment solved in 1410 episodes! \t Average Score: 0.699400\n",
      "\n",
      " Environment solved in 1411 episodes! \t Average Score: 0.699400\n",
      "\n",
      " Environment solved in 1412 episodes! \t Average Score: 0.683400\n",
      "\n",
      " Environment solved in 1413 episodes! \t Average Score: 0.687400\n",
      "\n",
      " Environment solved in 1414 episodes! \t Average Score: 0.665400\n",
      "\n",
      " Environment solved in 1415 episodes! \t Average Score: 0.663400\n",
      "\n",
      " Environment solved in 1416 episodes! \t Average Score: 0.661400\n",
      "\n",
      " Environment solved in 1417 episodes! \t Average Score: 0.659400\n",
      "\n",
      " Environment solved in 1418 episodes! \t Average Score: 0.658400\n",
      "\n",
      " Environment solved in 1419 episodes! \t Average Score: 0.652400\n",
      "Episode 1420\tAverage Score: 0.65\tAgent 1 Score: 0.00\tAgent 2 Score: 0.09\n",
      "\n",
      " Environment solved in 1420 episodes! \t Average Score: 0.646300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Environment solved in 1421 episodes! \t Average Score: 0.646300\n",
      "\n",
      " Environment solved in 1422 episodes! \t Average Score: 0.648300\n",
      "\n",
      " Environment solved in 1423 episodes! \t Average Score: 0.623300\n",
      "\n",
      " Environment solved in 1424 episodes! \t Average Score: 0.598300\n",
      "\n",
      " Environment solved in 1425 episodes! \t Average Score: 0.593300\n",
      "\n",
      " Environment solved in 1426 episodes! \t Average Score: 0.572300\n",
      "\n",
      " Environment solved in 1427 episodes! \t Average Score: 0.572300\n",
      "\n",
      " Environment solved in 1428 episodes! \t Average Score: 0.573300\n",
      "\n",
      " Environment solved in 1429 episodes! \t Average Score: 0.574300\n",
      "Episode 1430\tAverage Score: 0.57\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "\n",
      " Environment solved in 1430 episodes! \t Average Score: 0.573300\n",
      "\n",
      " Environment solved in 1431 episodes! \t Average Score: 0.571300\n",
      "\n",
      " Environment solved in 1432 episodes! \t Average Score: 0.575300\n",
      "\n",
      " Environment solved in 1433 episodes! \t Average Score: 0.578300\n",
      "\n",
      " Environment solved in 1434 episodes! \t Average Score: 0.576200\n",
      "\n",
      " Environment solved in 1435 episodes! \t Average Score: 0.577200\n",
      "\n",
      " Environment solved in 1436 episodes! \t Average Score: 0.578200\n",
      "\n",
      " Environment solved in 1437 episodes! \t Average Score: 0.578200\n",
      "\n",
      " Environment solved in 1438 episodes! \t Average Score: 0.578200\n",
      "\n",
      " Environment solved in 1439 episodes! \t Average Score: 0.582100\n",
      "Episode 1440\tAverage Score: 0.57\tAgent 1 Score: 0.10\tAgent 2 Score: -0.01\n",
      "\n",
      " Environment solved in 1440 episodes! \t Average Score: 0.569100\n",
      "\n",
      " Environment solved in 1441 episodes! \t Average Score: 0.556100\n",
      "\n",
      " Environment solved in 1442 episodes! \t Average Score: 0.534100\n",
      "\n",
      " Environment solved in 1443 episodes! \t Average Score: 0.509100\n",
      "Episode 1450\tAverage Score: 0.40\tAgent 1 Score: 0.20\tAgent 2 Score: 0.09\n",
      "Episode 1460\tAverage Score: 0.30\tAgent 1 Score: 0.10\tAgent 2 Score: -0.01\n",
      "Episode 1470\tAverage Score: 0.27\tAgent 1 Score: 0.10\tAgent 2 Score: -0.01\n",
      "Episode 1480\tAverage Score: 0.22\tAgent 1 Score: 0.09\tAgent 2 Score: 0.20\n",
      "Episode 1490\tAverage Score: 0.20\tAgent 1 Score: 0.29\tAgent 2 Score: 0.40\n",
      "Episode 1500\tAverage Score: 0.20\tAgent 1 Score: 0.30\tAgent 2 Score: 0.39\n",
      "Episode 1510\tAverage Score: 0.18\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "Episode 1520\tAverage Score: 0.18\tAgent 1 Score: 0.10\tAgent 2 Score: -0.01\n",
      "Episode 1530\tAverage Score: 0.17\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "Episode 1540\tAverage Score: 0.15\tAgent 1 Score: 0.30\tAgent 2 Score: 0.19\n",
      "Episode 1550\tAverage Score: 0.14\tAgent 1 Score: 0.10\tAgent 2 Score: -0.01\n",
      "Episode 1560\tAverage Score: 0.17\tAgent 1 Score: 1.10\tAgent 2 Score: 1.09\n",
      "Episode 1570\tAverage Score: 0.22\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "Episode 1580\tAverage Score: 0.31\tAgent 1 Score: 0.60\tAgent 2 Score: 0.59\n",
      "Episode 1590\tAverage Score: 0.36\tAgent 1 Score: 0.60\tAgent 2 Score: 0.49\n",
      "Episode 1600\tAverage Score: 0.38\tAgent 1 Score: 0.60\tAgent 2 Score: 0.59\n",
      "Episode 1610\tAverage Score: 0.40\tAgent 1 Score: 0.50\tAgent 2 Score: 0.39\n",
      "Episode 1620\tAverage Score: 0.40\tAgent 1 Score: 0.30\tAgent 2 Score: 0.19\n",
      "Episode 1630\tAverage Score: 0.43\tAgent 1 Score: 0.60\tAgent 2 Score: 0.59\n",
      "Episode 1640\tAverage Score: 0.46\tAgent 1 Score: 1.30\tAgent 2 Score: 1.29\n",
      "\n",
      " Environment solved in 1647 episodes! \t Average Score: 0.510200\n",
      "\n",
      " Environment solved in 1648 episodes! \t Average Score: 0.518200\n",
      "\n",
      " Environment solved in 1649 episodes! \t Average Score: 0.521200\n",
      "Episode 1650\tAverage Score: 0.53\tAgent 1 Score: 0.70\tAgent 2 Score: 0.59\n",
      "\n",
      " Environment solved in 1650 episodes! \t Average Score: 0.527200\n",
      "\n",
      " Environment solved in 1651 episodes! \t Average Score: 0.527200\n",
      "\n",
      " Environment solved in 1652 episodes! \t Average Score: 0.534200\n",
      "\n",
      " Environment solved in 1653 episodes! \t Average Score: 0.531200\n",
      "\n",
      " Environment solved in 1654 episodes! \t Average Score: 0.537200\n",
      "\n",
      " Environment solved in 1655 episodes! \t Average Score: 0.541200\n",
      "\n",
      " Environment solved in 1656 episodes! \t Average Score: 0.567200\n",
      "\n",
      " Environment solved in 1657 episodes! \t Average Score: 0.586200\n",
      "\n",
      " Environment solved in 1658 episodes! \t Average Score: 0.608200\n",
      "\n",
      " Environment solved in 1659 episodes! \t Average Score: 0.597200\n",
      "Episode 1660\tAverage Score: 0.61\tAgent 1 Score: 2.10\tAgent 2 Score: 2.09\n",
      "\n",
      " Environment solved in 1660 episodes! \t Average Score: 0.607200\n",
      "\n",
      " Environment solved in 1661 episodes! \t Average Score: 0.625200\n",
      "\n",
      " Environment solved in 1662 episodes! \t Average Score: 0.650300\n",
      "\n",
      " Environment solved in 1663 episodes! \t Average Score: 0.646300\n",
      "\n",
      " Environment solved in 1664 episodes! \t Average Score: 0.661300\n",
      "\n",
      " Environment solved in 1665 episodes! \t Average Score: 0.661400\n",
      "\n",
      " Environment solved in 1666 episodes! \t Average Score: 0.641400\n",
      "\n",
      " Environment solved in 1667 episodes! \t Average Score: 0.636400\n",
      "\n",
      " Environment solved in 1668 episodes! \t Average Score: 0.661400\n",
      "\n",
      " Environment solved in 1669 episodes! \t Average Score: 0.687400\n",
      "Episode 1670\tAverage Score: 0.69\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "\n",
      " Environment solved in 1670 episodes! \t Average Score: 0.687400\n",
      "\n",
      " Environment solved in 1671 episodes! \t Average Score: 0.673400\n",
      "\n",
      " Environment solved in 1672 episodes! \t Average Score: 0.688400\n",
      "\n",
      " Environment solved in 1673 episodes! \t Average Score: 0.714400\n",
      "\n",
      " Environment solved in 1674 episodes! \t Average Score: 0.738400\n",
      "\n",
      " Environment solved in 1675 episodes! \t Average Score: 0.753400\n",
      "\n",
      " Environment solved in 1676 episodes! \t Average Score: 0.771400\n",
      "\n",
      " Environment solved in 1677 episodes! \t Average Score: 0.776400\n",
      "\n",
      " Environment solved in 1678 episodes! \t Average Score: 0.776400\n",
      "\n",
      " Environment solved in 1679 episodes! \t Average Score: 0.778400\n",
      "Episode 1680\tAverage Score: 0.77\tAgent 1 Score: -0.01\tAgent 2 Score: 0.10\n",
      "\n",
      " Environment solved in 1680 episodes! \t Average Score: 0.773400\n",
      "\n",
      " Environment solved in 1681 episodes! \t Average Score: 0.774400\n",
      "\n",
      " Environment solved in 1682 episodes! \t Average Score: 0.794400\n",
      "\n",
      " Environment solved in 1683 episodes! \t Average Score: 0.791400\n",
      "\n",
      " Environment solved in 1684 episodes! \t Average Score: 0.787400\n",
      "\n",
      " Environment solved in 1685 episodes! \t Average Score: 0.807400\n",
      "\n",
      " Environment solved in 1686 episodes! \t Average Score: 0.826300\n",
      "\n",
      " Environment solved in 1687 episodes! \t Average Score: 0.811300\n",
      "\n",
      " Environment solved in 1688 episodes! \t Average Score: 0.809300\n",
      "\n",
      " Environment solved in 1689 episodes! \t Average Score: 0.822300\n",
      "Episode 1690\tAverage Score: 0.83\tAgent 1 Score: 1.29\tAgent 2 Score: 1.30\n",
      "\n",
      " Environment solved in 1690 episodes! \t Average Score: 0.829300\n",
      "\n",
      " Environment solved in 1691 episodes! \t Average Score: 0.830300\n",
      "\n",
      " Environment solved in 1692 episodes! \t Average Score: 0.832300\n",
      "\n",
      " Environment solved in 1693 episodes! \t Average Score: 0.834200\n",
      "\n",
      " Environment solved in 1694 episodes! \t Average Score: 0.842200\n",
      "\n",
      " Environment solved in 1695 episodes! \t Average Score: 0.863200\n",
      "\n",
      " Environment solved in 1696 episodes! \t Average Score: 0.875200\n",
      "\n",
      " Environment solved in 1697 episodes! \t Average Score: 0.889300\n",
      "\n",
      " Environment solved in 1698 episodes! \t Average Score: 0.882400\n",
      "\n",
      " Environment solved in 1699 episodes! \t Average Score: 0.884400\n",
      "Episode 1700\tAverage Score: 0.89\tAgent 1 Score: 1.10\tAgent 2 Score: 1.19\n",
      "\n",
      " Environment solved in 1700 episodes! \t Average Score: 0.890300\n",
      "\n",
      " Environment solved in 1701 episodes! \t Average Score: 0.885300\n",
      "\n",
      " Environment solved in 1702 episodes! \t Average Score: 0.882300\n",
      "\n",
      " Environment solved in 1703 episodes! \t Average Score: 0.883300\n",
      "\n",
      " Environment solved in 1704 episodes! \t Average Score: 0.881300\n",
      "\n",
      " Environment solved in 1705 episodes! \t Average Score: 0.879200\n",
      "\n",
      " Environment solved in 1706 episodes! \t Average Score: 0.884200\n",
      "\n",
      " Environment solved in 1707 episodes! \t Average Score: 0.884100\n",
      "\n",
      " Environment solved in 1708 episodes! \t Average Score: 0.886100\n",
      "\n",
      " Environment solved in 1709 episodes! \t Average Score: 0.891100\n",
      "Episode 1710\tAverage Score: 0.89\tAgent 1 Score: 0.40\tAgent 2 Score: 0.49\n",
      "\n",
      " Environment solved in 1710 episodes! \t Average Score: 0.891000\n",
      "\n",
      " Environment solved in 1711 episodes! \t Average Score: 0.891100\n",
      "\n",
      " Environment solved in 1712 episodes! \t Average Score: 0.900100\n",
      "\n",
      " Environment solved in 1713 episodes! \t Average Score: 0.899100\n",
      "\n",
      " Environment solved in 1714 episodes! \t Average Score: 0.904100\n",
      "\n",
      " Environment solved in 1715 episodes! \t Average Score: 0.907100\n",
      "\n",
      " Environment solved in 1716 episodes! \t Average Score: 0.909100\n",
      "\n",
      " Environment solved in 1717 episodes! \t Average Score: 0.910100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Environment solved in 1718 episodes! \t Average Score: 0.910100\n",
      "\n",
      " Environment solved in 1719 episodes! \t Average Score: 0.916000\n",
      "Episode 1720\tAverage Score: 0.91\tAgent 1 Score: 0.10\tAgent 2 Score: -0.01\n",
      "\n",
      " Environment solved in 1720 episodes! \t Average Score: 0.914000\n",
      "\n",
      " Environment solved in 1721 episodes! \t Average Score: 0.912000\n",
      "\n",
      " Environment solved in 1722 episodes! \t Average Score: 0.910000\n",
      "\n",
      " Environment solved in 1723 episodes! \t Average Score: 0.904000\n",
      "\n",
      " Environment solved in 1724 episodes! \t Average Score: 0.901000\n",
      "\n",
      " Environment solved in 1725 episodes! \t Average Score: 0.898900\n",
      "\n",
      " Environment solved in 1726 episodes! \t Average Score: 0.891900\n",
      "\n",
      " Environment solved in 1727 episodes! \t Average Score: 0.893900\n",
      "\n",
      " Environment solved in 1728 episodes! \t Average Score: 0.918900\n",
      "\n",
      " Environment solved in 1729 episodes! \t Average Score: 0.935800\n",
      "Episode 1730\tAverage Score: 0.93\tAgent 1 Score: -0.01\tAgent 2 Score: 0.00\n",
      "\n",
      " Environment solved in 1730 episodes! \t Average Score: 0.929800\n",
      "\n",
      " Environment solved in 1731 episodes! \t Average Score: 0.940800\n",
      "\n",
      " Environment solved in 1732 episodes! \t Average Score: 0.933800\n",
      "\n",
      " Environment solved in 1733 episodes! \t Average Score: 0.933800\n",
      "\n",
      " Environment solved in 1734 episodes! \t Average Score: 0.935900\n",
      "\n",
      " Environment solved in 1735 episodes! \t Average Score: 0.931900\n",
      "\n",
      " Environment solved in 1736 episodes! \t Average Score: 0.932900\n",
      "\n",
      " Environment solved in 1737 episodes! \t Average Score: 0.937800\n",
      "\n",
      " Environment solved in 1738 episodes! \t Average Score: 0.948800\n",
      "\n",
      " Environment solved in 1739 episodes! \t Average Score: 0.953900\n",
      "Episode 1740\tAverage Score: 0.95\tAgent 1 Score: 0.80\tAgent 2 Score: 0.69\n",
      "\n",
      " Environment solved in 1740 episodes! \t Average Score: 0.948900\n",
      "\n",
      " Environment solved in 1741 episodes! \t Average Score: 0.947900\n",
      "\n",
      " Environment solved in 1742 episodes! \t Average Score: 0.943900\n",
      "\n",
      " Environment solved in 1743 episodes! \t Average Score: 0.940000\n",
      "\n",
      " Environment solved in 1744 episodes! \t Average Score: 0.934000\n",
      "\n",
      " Environment solved in 1745 episodes! \t Average Score: 0.935000\n",
      "\n",
      " Environment solved in 1746 episodes! \t Average Score: 0.948000\n",
      "\n",
      " Environment solved in 1747 episodes! \t Average Score: 0.962000\n",
      "\n",
      " Environment solved in 1748 episodes! \t Average Score: 0.955000\n",
      "\n",
      " Environment solved in 1749 episodes! \t Average Score: 0.953000\n",
      "Episode 1750\tAverage Score: 0.96\tAgent 1 Score: 1.80\tAgent 2 Score: 1.79\n",
      "\n",
      " Environment solved in 1750 episodes! \t Average Score: 0.964000\n",
      "\n",
      " Environment solved in 1751 episodes! \t Average Score: 0.961000\n",
      "\n",
      " Environment solved in 1752 episodes! \t Average Score: 0.961000\n",
      "\n",
      " Environment solved in 1753 episodes! \t Average Score: 0.971000\n",
      "\n",
      " Environment solved in 1754 episodes! \t Average Score: 0.967000\n",
      "\n",
      " Environment solved in 1755 episodes! \t Average Score: 0.988000\n",
      "\n",
      " Environment solved in 1756 episodes! \t Average Score: 0.963000\n",
      "\n",
      " Environment solved in 1757 episodes! \t Average Score: 0.938000\n",
      "\n",
      " Environment solved in 1758 episodes! \t Average Score: 0.925900\n",
      "\n",
      " Environment solved in 1759 episodes! \t Average Score: 0.926900\n",
      "Episode 1760\tAverage Score: 0.91\tAgent 1 Score: 0.10\tAgent 2 Score: -0.01\n",
      "\n",
      " Environment solved in 1760 episodes! \t Average Score: 0.906900\n",
      "\n",
      " Environment solved in 1761 episodes! \t Average Score: 0.881900\n",
      "\n",
      " Environment solved in 1762 episodes! \t Average Score: 0.859900\n",
      "\n",
      " Environment solved in 1763 episodes! \t Average Score: 0.860900\n",
      "\n",
      " Environment solved in 1764 episodes! \t Average Score: 0.835900\n",
      "\n",
      " Environment solved in 1765 episodes! \t Average Score: 0.833900\n",
      "\n",
      " Environment solved in 1766 episodes! \t Average Score: 0.834900\n",
      "\n",
      " Environment solved in 1767 episodes! \t Average Score: 0.843900\n",
      "\n",
      " Environment solved in 1768 episodes! \t Average Score: 0.822900\n",
      "\n",
      " Environment solved in 1769 episodes! \t Average Score: 0.798900\n",
      "Episode 1770\tAverage Score: 0.80\tAgent 1 Score: 0.10\tAgent 2 Score: -0.01\n",
      "\n",
      " Environment solved in 1770 episodes! \t Average Score: 0.799900\n",
      "\n",
      " Environment solved in 1771 episodes! \t Average Score: 0.789900\n",
      "\n",
      " Environment solved in 1772 episodes! \t Average Score: 0.764900\n",
      "\n",
      " Environment solved in 1773 episodes! \t Average Score: 0.745900\n",
      "\n",
      " Environment solved in 1774 episodes! \t Average Score: 0.721900\n",
      "\n",
      " Environment solved in 1775 episodes! \t Average Score: 0.699900\n",
      "\n",
      " Environment solved in 1776 episodes! \t Average Score: 0.681900\n",
      "\n",
      " Environment solved in 1777 episodes! \t Average Score: 0.657900\n",
      "\n",
      " Environment solved in 1778 episodes! \t Average Score: 0.638900\n",
      "\n",
      " Environment solved in 1779 episodes! \t Average Score: 0.632900\n",
      "Episode 1780\tAverage Score: 0.63\tAgent 1 Score: 0.10\tAgent 2 Score: -0.01\n",
      "\n",
      " Environment solved in 1780 episodes! \t Average Score: 0.632900\n",
      "\n",
      " Environment solved in 1781 episodes! \t Average Score: 0.631900\n",
      "\n",
      " Environment solved in 1782 episodes! \t Average Score: 0.606900\n",
      "\n",
      " Environment solved in 1783 episodes! \t Average Score: 0.603900\n",
      "\n",
      " Environment solved in 1784 episodes! \t Average Score: 0.604900\n",
      "\n",
      " Environment solved in 1785 episodes! \t Average Score: 0.581900\n",
      "\n",
      " Environment solved in 1786 episodes! \t Average Score: 0.558000\n",
      "\n",
      " Environment solved in 1787 episodes! \t Average Score: 0.567000\n",
      "\n",
      " Environment solved in 1788 episodes! \t Average Score: 0.567000\n",
      "\n",
      " Environment solved in 1789 episodes! \t Average Score: 0.549000\n",
      "Episode 1790\tAverage Score: 0.54\tAgent 1 Score: 0.10\tAgent 2 Score: -0.01\n",
      "\n",
      " Environment solved in 1790 episodes! \t Average Score: 0.537000\n",
      "\n",
      " Environment solved in 1791 episodes! \t Average Score: 0.536900\n",
      "\n",
      " Environment solved in 1792 episodes! \t Average Score: 0.535900\n",
      "\n",
      " Environment solved in 1793 episodes! \t Average Score: 0.540000\n",
      "\n",
      " Environment solved in 1794 episodes! \t Average Score: 0.532000\n",
      "\n",
      " Environment solved in 1795 episodes! \t Average Score: 0.510000\n",
      "\n",
      " Environment solved in 1796 episodes! \t Average Score: 0.502000\n",
      "Episode 1800\tAverage Score: 0.49\tAgent 1 Score: 1.29\tAgent 2 Score: 1.40\n",
      "\n",
      " Environment solved in 1803 episodes! \t Average Score: 0.503100\n",
      "\n",
      " Environment solved in 1804 episodes! \t Average Score: 0.502100\n",
      "\n",
      " Environment solved in 1805 episodes! \t Average Score: 0.502200\n",
      "\n",
      " Environment solved in 1806 episodes! \t Average Score: 0.507200\n",
      "\n",
      " Environment solved in 1807 episodes! \t Average Score: 0.526300\n",
      "\n",
      " Environment solved in 1808 episodes! \t Average Score: 0.533300\n",
      "\n",
      " Environment solved in 1809 episodes! \t Average Score: 0.526300\n",
      "Episode 1810\tAverage Score: 0.52\tAgent 1 Score: 0.00\tAgent 2 Score: 0.09\n",
      "\n",
      " Environment solved in 1810 episodes! \t Average Score: 0.522300\n",
      "\n",
      " Environment solved in 1811 episodes! \t Average Score: 0.541300\n",
      "\n",
      " Environment solved in 1812 episodes! \t Average Score: 0.533300\n",
      "\n",
      " Environment solved in 1813 episodes! \t Average Score: 0.533300\n",
      "\n",
      " Environment solved in 1814 episodes! \t Average Score: 0.528300\n",
      "\n",
      " Environment solved in 1815 episodes! \t Average Score: 0.525300\n",
      "\n",
      " Environment solved in 1816 episodes! \t Average Score: 0.548300\n",
      "\n",
      " Environment solved in 1817 episodes! \t Average Score: 0.546300\n",
      "\n",
      " Environment solved in 1818 episodes! \t Average Score: 0.546300\n",
      "\n",
      " Environment solved in 1819 episodes! \t Average Score: 0.539400\n",
      "Episode 1820\tAverage Score: 0.54\tAgent 1 Score: 0.19\tAgent 2 Score: 0.20\n",
      "\n",
      " Environment solved in 1820 episodes! \t Average Score: 0.540400\n",
      "\n",
      " Environment solved in 1821 episodes! \t Average Score: 0.540400\n",
      "\n",
      " Environment solved in 1822 episodes! \t Average Score: 0.548400\n",
      "\n",
      " Environment solved in 1823 episodes! \t Average Score: 0.550300\n",
      "\n",
      " Environment solved in 1824 episodes! \t Average Score: 0.549300\n",
      "\n",
      " Environment solved in 1825 episodes! \t Average Score: 0.549400\n",
      "\n",
      " Environment solved in 1826 episodes! \t Average Score: 0.550400\n",
      "\n",
      " Environment solved in 1827 episodes! \t Average Score: 0.545300\n",
      "\n",
      " Environment solved in 1828 episodes! \t Average Score: 0.528300\n",
      "\n",
      " Environment solved in 1829 episodes! \t Average Score: 0.507400\n",
      "Episode 1830\tAverage Score: 0.51\tAgent 1 Score: 0.39\tAgent 2 Score: 0.50\n",
      "\n",
      " Environment solved in 1830 episodes! \t Average Score: 0.512400\n",
      "\n",
      " Environment solved in 1831 episodes! \t Average Score: 0.500400\n",
      "\n",
      " Environment solved in 1832 episodes! \t Average Score: 0.503400\n",
      "\n",
      " Environment solved in 1833 episodes! \t Average Score: 0.505300\n",
      "\n",
      " Environment solved in 1835 episodes! \t Average Score: 0.510300\n",
      "\n",
      " Environment solved in 1836 episodes! \t Average Score: 0.510300\n",
      "\n",
      " Environment solved in 1837 episodes! \t Average Score: 0.505300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1840\tAverage Score: 0.48\tAgent 1 Score: -0.01\tAgent 2 Score: 0.10\n",
      "Episode 1850\tAverage Score: 0.41\tAgent 1 Score: 0.10\tAgent 2 Score: -0.01\n",
      "Episode 1860\tAverage Score: 0.37\tAgent 1 Score: 0.00\tAgent 2 Score: 0.09\n",
      "Episode 1870\tAverage Score: 0.40\tAgent 1 Score: 1.40\tAgent 2 Score: 1.29\n",
      "Episode 1880\tAverage Score: 0.42\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "\n",
      " Environment solved in 1889 episodes! \t Average Score: 0.511800\n",
      "Episode 1890\tAverage Score: 0.51\tAgent 1 Score: 0.09\tAgent 2 Score: 0.10\n",
      "\n",
      " Environment solved in 1890 episodes! \t Average Score: 0.511800\n",
      "\n",
      " Environment solved in 1891 episodes! \t Average Score: 0.512900\n",
      "\n",
      " Environment solved in 1892 episodes! \t Average Score: 0.525900\n",
      "\n",
      " Environment solved in 1893 episodes! \t Average Score: 0.520900\n",
      "\n",
      " Environment solved in 1894 episodes! \t Average Score: 0.527900\n",
      "\n",
      " Environment solved in 1895 episodes! \t Average Score: 0.531900\n",
      "\n",
      " Environment solved in 1896 episodes! \t Average Score: 0.533900\n",
      "\n",
      " Environment solved in 1897 episodes! \t Average Score: 0.538900\n",
      "\n",
      " Environment solved in 1898 episodes! \t Average Score: 0.533900\n",
      "\n",
      " Environment solved in 1899 episodes! \t Average Score: 0.533800\n",
      "Episode 1900\tAverage Score: 0.53\tAgent 1 Score: 1.30\tAgent 2 Score: 1.29\n",
      "\n",
      " Environment solved in 1900 episodes! \t Average Score: 0.532800\n",
      "\n",
      " Environment solved in 1901 episodes! \t Average Score: 0.530800\n",
      "\n",
      " Environment solved in 1902 episodes! \t Average Score: 0.523800\n",
      "\n",
      " Environment solved in 1903 episodes! \t Average Score: 0.520800\n",
      "\n",
      " Environment solved in 1904 episodes! \t Average Score: 0.528800\n",
      "\n",
      " Environment solved in 1905 episodes! \t Average Score: 0.529800\n",
      "\n",
      " Environment solved in 1906 episodes! \t Average Score: 0.519800\n",
      "\n",
      " Environment solved in 1907 episodes! \t Average Score: 0.500800\n",
      "Episode 1910\tAverage Score: 0.49\tAgent 1 Score: 0.30\tAgent 2 Score: 0.29\n",
      "Episode 1920\tAverage Score: 0.47\tAgent 1 Score: 0.40\tAgent 2 Score: 0.39\n",
      "Episode 1930\tAverage Score: 0.49\tAgent 1 Score: 0.30\tAgent 2 Score: 0.19\n",
      "Episode 1940\tAverage Score: 0.49\tAgent 1 Score: 0.90\tAgent 2 Score: 0.99\n",
      "\n",
      " Environment solved in 1942 episodes! \t Average Score: 0.502700\n",
      "\n",
      " Environment solved in 1943 episodes! \t Average Score: 0.503700\n",
      "\n",
      " Environment solved in 1944 episodes! \t Average Score: 0.503700\n",
      "\n",
      " Environment solved in 1945 episodes! \t Average Score: 0.504700\n",
      "\n",
      " Environment solved in 1946 episodes! \t Average Score: 0.506700\n",
      "\n",
      " Environment solved in 1947 episodes! \t Average Score: 0.506700\n",
      "\n",
      " Environment solved in 1948 episodes! \t Average Score: 0.506700\n",
      "\n",
      " Environment solved in 1949 episodes! \t Average Score: 0.509600\n",
      "Episode 1950\tAverage Score: 0.51\tAgent 1 Score: 0.50\tAgent 2 Score: 0.49\n",
      "\n",
      " Environment solved in 1950 episodes! \t Average Score: 0.513600\n",
      "\n",
      " Environment solved in 1951 episodes! \t Average Score: 0.521600\n",
      "\n",
      " Environment solved in 1952 episodes! \t Average Score: 0.526500\n",
      "\n",
      " Environment solved in 1953 episodes! \t Average Score: 0.529500\n",
      "\n",
      " Environment solved in 1954 episodes! \t Average Score: 0.528400\n",
      "\n",
      " Environment solved in 1955 episodes! \t Average Score: 0.529400\n",
      "\n",
      " Environment solved in 1956 episodes! \t Average Score: 0.531400\n",
      "\n",
      " Environment solved in 1957 episodes! \t Average Score: 0.521300\n",
      "\n",
      " Environment solved in 1958 episodes! \t Average Score: 0.518300\n",
      "\n",
      " Environment solved in 1959 episodes! \t Average Score: 0.518400\n",
      "Episode 1960\tAverage Score: 0.52\tAgent 1 Score: 0.19\tAgent 2 Score: 0.20\n",
      "\n",
      " Environment solved in 1960 episodes! \t Average Score: 0.519500\n",
      "\n",
      " Environment solved in 1961 episodes! \t Average Score: 0.521500\n",
      "\n",
      " Environment solved in 1962 episodes! \t Average Score: 0.523400\n",
      "\n",
      " Environment solved in 1963 episodes! \t Average Score: 0.525300\n",
      "\n",
      " Environment solved in 1964 episodes! \t Average Score: 0.521300\n",
      "\n",
      " Environment solved in 1965 episodes! \t Average Score: 0.507300\n",
      "\n",
      " Environment solved in 1966 episodes! \t Average Score: 0.511300\n",
      "\n",
      " Environment solved in 1967 episodes! \t Average Score: 0.511200\n",
      "\n",
      " Environment solved in 1968 episodes! \t Average Score: 0.507200\n",
      "\n",
      " Environment solved in 1969 episodes! \t Average Score: 0.507200\n",
      "Episode 1970\tAverage Score: 0.50\tAgent 1 Score: 0.20\tAgent 2 Score: 0.19\n",
      "Episode 1980\tAverage Score: 0.50\tAgent 1 Score: 0.60\tAgent 2 Score: 0.59\n",
      "\n",
      " Environment solved in 1982 episodes! \t Average Score: 0.521300\n",
      "\n",
      " Environment solved in 1983 episodes! \t Average Score: 0.506300\n",
      "\n",
      " Environment solved in 1984 episodes! \t Average Score: 0.519200\n",
      "\n",
      " Environment solved in 1985 episodes! \t Average Score: 0.517200\n",
      "\n",
      " Environment solved in 1986 episodes! \t Average Score: 0.525200\n",
      "\n",
      " Environment solved in 1987 episodes! \t Average Score: 0.506200\n",
      "\n",
      " Environment solved in 1988 episodes! \t Average Score: 0.511200\n",
      "\n",
      " Environment solved in 1989 episodes! \t Average Score: 0.508200\n",
      "Episode 1990\tAverage Score: 0.51\tAgent 1 Score: 0.00\tAgent 2 Score: -0.01\n",
      "\n",
      " Environment solved in 1990 episodes! \t Average Score: 0.507200\n",
      "\n",
      " Environment solved in 1991 episodes! \t Average Score: 0.526200\n",
      "\n",
      " Environment solved in 1992 episodes! \t Average Score: 0.520200\n",
      "\n",
      " Environment solved in 1993 episodes! \t Average Score: 0.519200\n",
      "\n",
      " Environment solved in 1994 episodes! \t Average Score: 0.512200\n",
      "\n",
      " Environment solved in 1995 episodes! \t Average Score: 0.507200\n",
      "\n",
      " Environment solved in 1996 episodes! \t Average Score: 0.503100\n",
      "\n",
      " Environment solved in 1997 episodes! \t Average Score: 0.502100\n",
      "\n",
      " Environment solved in 1998 episodes! \t Average Score: 0.511100\n",
      "\n",
      " Environment solved in 1999 episodes! \t Average Score: 0.511200\n",
      "Episode 2000\tAverage Score: 0.50\tAgent 1 Score: 0.10\tAgent 2 Score: 0.19\n",
      "\n",
      " Environment solved in 2000 episodes! \t Average Score: 0.500100\n"
     ]
    }
   ],
   "source": [
    "from ddpg_multiAgent import MultiAgent\n",
    "multiAgent = MultiAgent(state_size=state_size, action_size=action_size, random_seed=2, num_agents = num_agents)\n",
    "# print('params=', multiAgent.params)\n",
    "\n",
    "from constant_params import constParams\n",
    "params = constParams()\n",
    "\n",
    "def maddpg(n_episodes=params.max_episodes, max_t=500000, print_every=100):\n",
    "    scores_deque = deque(maxlen=print_every)\n",
    "    scores = []\n",
    "    scores_movingAvg = []\n",
    "    scores_mean = []\n",
    "    \n",
    "    for i_episode in range(1, n_episodes+1):        \n",
    "        env_info = env.reset(train_mode=True)[brain_name] # reset the environment\n",
    "        state = env_info.vector_observations            # get the current state\n",
    "        multiAgent.reset()\n",
    "        scores = np.zeros(num_agents)\n",
    "        for t in range(max_t):\n",
    "#             epsilon = max(params.epsilon_start-i_episode*params.epsilon_decay_rate,0.1)#decaying epsilon value\n",
    "            epsilon = 0.1 \n",
    "        \n",
    "            action = multiAgent.act(state, epsilon, add_noise=True)# select an action (for each agent)\n",
    "#             action = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "#             action = np.clip(action, -1, 1)                  # all actions between -1 and 1\n",
    "#             print('states=', state)\n",
    "#             print('actions=', action)\n",
    "            env_info = env.step(action)[brain_name]           # send all actions to tne environment\n",
    "#             print('envinfo=', env_info)\n",
    "            next_state = env_info.vector_observations         # get next state (for each agent)\n",
    "            rewards = env_info.rewards                         # get reward (for each agent)\n",
    "            dones = env_info.local_done                        # see if episode finished\n",
    "            \n",
    "            multiAgent.step(state, action, rewards, next_state, dones)    \n",
    "            scores += env_info.rewards                         # update the score (for each agent)\n",
    "            state = next_state                               # roll over states to next time step\n",
    "            if np.any(dones):                                  # exit loop if episode finished\n",
    "                break\n",
    "    \n",
    "    \n",
    "        scores_deque.append(np.max(scores))\n",
    "        scores_movingAvg.append(np.mean(scores_deque))\n",
    "        \n",
    "        if i_episode % 10 == 0:\n",
    "#             print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_deque)))\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}\\tAgent 1 Score: {:.2f}\\tAgent 2 Score: {:.2f}'.format(i_episode,scores_movingAvg[-1],scores[0],scores[1]))\n",
    "#             print('epsilon=', epsilon)\n",
    "\n",
    "        if np.mean(scores_deque)>= 0.5 and i_episode >= 100:\n",
    "            print('\\n Environment solved in {:d} episodes! \\t Average Score: {:2f}'.format(i_episode, np.mean(scores_deque)))\n",
    "            for i, agent in enumerate(multiAgent.ddpg_agents):\n",
    "                torch.save(agent.actor_local.state_dict(), '\\trainedNN_actor_{}.pth'.format(i)) \n",
    "                torch.save(agent.critic_local.state_dict(), '\\trainedNN_critic_{}.pth'.format(i)) \n",
    "    return scores, scores_movingAvg\n",
    "\n",
    "scores, scores_movingAvg = maddpg()\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-db14d1220035>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m111\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Scores'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Average Scores'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Score'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scores' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff139e8a0f0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores, label='Scores')\n",
    "plt.plot(np.arange(len(scores)), scores_mean, c='m', label='Average Scores')\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.legend(loc='upper left');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: \t0 \tScore: \t2.60\n",
      "Episode: \t1 \tScore: \t-0.00\n",
      "Episode: \t2 \tScore: \t0.15\n"
     ]
    }
   ],
   "source": [
    "from ddpg_multiAgent import MultiAgent\n",
    "multiAgent = MultiAgent(state_size=state_size, action_size=action_size, random_seed=2, num_agents = num_agents)\n",
    "\n",
    "for i, agent in enumerate(multiAgent.ddpg_agents):\n",
    "    agent.actor_local.load_state_dict(torch.load('trainedNN_actor_{}.pth'.format(i), map_location='cpu'))\n",
    "    agent.actor_target.load_state_dict(torch.load('trainedNN_actor_{}.pth'.format(i), map_location='cpu'))\n",
    "    agent.critic_local.load_state_dict(torch.load('trainedNN_critic_{}.pth'.format(i), map_location='cpu'))\n",
    "    agent.critic_target.load_state_dict(torch.load('trainedNN_critic_{}.pth'.format(i), map_location='cpu'))\n",
    "\n",
    "for episode in range(3):\n",
    "    env_info = env.reset(train_mode=False)[brain_name]        \n",
    "    states = env_info.vector_observations       \n",
    "    score = np.zeros(num_agents)               \n",
    "    while True:\n",
    "        actions = multiAgent.act(states, epsilon=0, add_noise=False)                       \n",
    "        env_info = env.step(actions)[brain_name]        \n",
    "        next_states = env_info.vector_observations     \n",
    "        rewards = env_info.rewards       \n",
    "        dones = env_info.local_done\n",
    "        score += rewards\n",
    "        states = next_states\n",
    "        if np.any(dones):                              \n",
    "            break\n",
    "    print('Episode: \\t{} \\tScore: \\t{:.2f}'.format(episode, np.mean(score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
